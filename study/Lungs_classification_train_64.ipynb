{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ Image Files resize (64x64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  cv2\n",
    "import  os \n",
    "import  numpy  as np\n",
    "\n",
    "path = \"E:\\\\data11\\\\original\"\n",
    "\n",
    "file_list = os.listdir(path)\n",
    "    \n",
    "for k in file_list:\n",
    "    img = cv2.imread(path + '\\\\' + k)\n",
    "    width, height = img.shape[:2]\n",
    "    resize_img = cv2.resize(img, (64 , 64), interpolation=cv2.INTER_CUBIC)\n",
    "    cv2.imwrite('E:\\\\data11\\\\resize_64\\\\' + k, resize_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ Setting\n",
    "\n",
    "#### ▶ Train_data (1 ~ 7000) :  7000개\n",
    "\n",
    "#### ▶ Test_data (7001 ~ 7470) : 470개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ Create Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ● Change 2 dimension array to 1 dimension array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "path1 = 'E:\\\\data11\\\\xray_labels.csv'\n",
    "file = open(path1)\n",
    "\n",
    "labeldata = csv.reader(file)\n",
    "labellist = []\n",
    "\n",
    "for  i   in  labeldata:\n",
    "    labellist.append(i)\n",
    "\n",
    "labellist2 = sum(labellist,[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ● Change 'normal' = 1 , 'patient' = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = 'E:\\\\data11\\\\xray_labels2.csv'\n",
    "file2 = open(path2, 'w')\n",
    "\n",
    "# normal = 1 , patient = 0\n",
    "\n",
    "for  i  in  labellist2:\n",
    "    if i == 'patient':\n",
    "        file2.write( str(0) + '\\n' )\n",
    "    else:\n",
    "        file2.write( str(1) + '\\n' )\n",
    "        \n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ● Save Train Labels and Test Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train labels\n",
    "\n",
    "path = 'E:\\\\data11\\\\xray_labels2.csv'\n",
    "file = open(path)\n",
    "\n",
    "labeldata = csv.reader(file)\n",
    "labellist = []\n",
    "\n",
    "for  i   in  labeldata:\n",
    "    labellist.append(i)\n",
    "\n",
    "labellist2 = sum(labellist,[]) # sum 함수의 default 값은 0이므로 []로 바꾸어서 리스트 합침.\n",
    "\n",
    "# print(labellist)\n",
    "\n",
    "\n",
    "path2 = 'E:\\\\data11\\\\train_label.csv'\n",
    "file2 = open(path2, 'w')\n",
    "\n",
    "for  i  in  range(0,7000):\n",
    "    file2.write( str(labellist2[i]) + '\\n' )\n",
    "    \n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save test labels\n",
    "\n",
    "path = 'E:\\\\data11\\\\xray_labels2.csv'\n",
    "file = open(path)\n",
    "\n",
    "labeldata = csv.reader(file)\n",
    "labellist = []\n",
    "\n",
    "for  i   in  labeldata:\n",
    "    labellist.append(i)\n",
    "\n",
    "labellist2 = sum(labellist,[]) # sum 함수의 default 값은 0이므로 []로 바꾸어서 리스트 합침.\n",
    "\n",
    "# print(labellist)\n",
    "\n",
    "\n",
    "path2 = 'E:\\\\data11\\\\test_label.csv'\n",
    "file2 = open(path2, 'w')\n",
    "\n",
    "for  i  in  range(7000,7470):\n",
    "    file2.write( str(labellist2[i]) + '\\n' )\n",
    "    \n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ Create loader4.py \n",
    "\n",
    " ■ image_load  \n",
    " ■ next_batch  \n",
    " ■ shuffle_batch  \n",
    " ■ label_load  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import   csv\n",
    "import  os\n",
    "import  re\n",
    "import  cv2\n",
    "import  random\n",
    "import  numpy  as  np\n",
    "\n",
    "def  image_load(path):\n",
    "    file_list = os.listdir(path)\n",
    "    file_name = []\n",
    "    for  i  in  file_list:\n",
    "        a = int(  re.sub('[^0-9]', '', i )  ) # 숫자가 아닌것은 '' 로 처리 \n",
    "        file_name.append(a) \n",
    "    file_name.sort()\n",
    "\n",
    "    file_res = [] \n",
    "    for  j  in   file_name:\n",
    "        file_res.append('%s\\\\%d.png' %(path,j)  )\n",
    "\n",
    "    image = []\n",
    "    for  k  in  file_res:\n",
    "        img = cv2.imread(k)\n",
    "        image.append(img)\n",
    "\n",
    "    return  np.array(image)\n",
    "\n",
    "def  label_load( path ):\n",
    "    file = open(path)\n",
    "    labeldata = csv.reader(file)\n",
    "    labellist = []\n",
    "    for  i   in  labeldata:\n",
    "        labellist.append(i)\n",
    "\n",
    "    label = np.array(labellist)\n",
    "    label = label.astype(int)  # 숫자로 변환 \n",
    "    label = np.eye(2)[label]\n",
    "    label = label.reshape(-1,2) \n",
    "    return  label\n",
    "\n",
    "\n",
    "def  shuffle_batch( data_list, label ):\n",
    "    x = np.arange( len( data_list) )\n",
    "    random.shuffle(x)\n",
    "    data_list2 = data_list[x]\n",
    "    label2 = label[x]\n",
    "    return   data_list2, label2 \n",
    "\n",
    "\n",
    "def  next_batch( data1, data2, init,  fina ):\n",
    "    return  data1[ init : fina ],  data2[init : fina] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ● Check train_data and test_data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 64, 64, 3)\n",
      "(7000, 2)\n",
      "(470, 64, 64, 3)\n",
      "(470, 2)\n"
     ]
    }
   ],
   "source": [
    "import loader4\n",
    "\n",
    "train_image='E:\\\\data11\\\\train_resize_64\\\\'\n",
    "train_label= 'E:\\\\data11\\\\train_label.csv'\n",
    "test_image='E:\\\\data11\\\\test_resize_64\\\\'\n",
    "test_label='E:\\\\data11\\\\test_label.csv'\n",
    "\n",
    "print(loader4.image_load(train_image).shape)\n",
    "print(loader4.label_load(train_label).shape)\n",
    "print(loader4.image_load(test_image).shape)\n",
    "print(loader4.label_load(test_label).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ Train start !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 64, 64, 3)\n",
      "(7000, 2)\n",
      "(470, 64, 64, 3)\n",
      "(470, 2)\n",
      "(64, 64, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\ipykernel_launcher.py:73: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 470 samples\n",
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 8s 1ms/step - loss: 0.8204 - accuracy: 0.5886 - val_loss: 0.6874 - val_accuracy: 0.6043\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 5s 783us/step - loss: 0.6721 - accuracy: 0.6230 - val_loss: 0.6658 - val_accuracy: 0.6043\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 5s 783us/step - loss: 0.6492 - accuracy: 0.6376 - val_loss: 0.6508 - val_accuracy: 0.6064\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 5s 767us/step - loss: 0.6343 - accuracy: 0.6476 - val_loss: 0.6416 - val_accuracy: 0.6255\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 5s 771us/step - loss: 0.6249 - accuracy: 0.6497 - val_loss: 0.6570 - val_accuracy: 0.6277\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 5s 770us/step - loss: 0.6136 - accuracy: 0.6639 - val_loss: 0.6781 - val_accuracy: 0.6106\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 5s 766us/step - loss: 0.6095 - accuracy: 0.6670 - val_loss: 0.6202 - val_accuracy: 0.6489\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 5s 769us/step - loss: 0.5970 - accuracy: 0.6726 - val_loss: 0.6324 - val_accuracy: 0.6447\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 5s 770us/step - loss: 0.5896 - accuracy: 0.6834 - val_loss: 0.6313 - val_accuracy: 0.6319\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 5s 770us/step - loss: 0.5779 - accuracy: 0.6943 - val_loss: 0.6355 - val_accuracy: 0.6511\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 5s 768us/step - loss: 0.5560 - accuracy: 0.7086 - val_loss: 0.6601 - val_accuracy: 0.6149\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 5s 769us/step - loss: 0.5455 - accuracy: 0.7147 - val_loss: 0.6410 - val_accuracy: 0.6447\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 5s 772us/step - loss: 0.5198 - accuracy: 0.7394 - val_loss: 0.6307 - val_accuracy: 0.6511\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 5s 769us/step - loss: 0.4995 - accuracy: 0.7519 - val_loss: 0.6763 - val_accuracy: 0.6191\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 6s 814us/step - loss: 0.4597 - accuracy: 0.7790 - val_loss: 0.6637 - val_accuracy: 0.6319\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 5s 763us/step - loss: 0.4283 - accuracy: 0.7984 - val_loss: 0.6941 - val_accuracy: 0.6447\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 5s 769us/step - loss: 0.3894 - accuracy: 0.8217 - val_loss: 0.7100 - val_accuracy: 0.6340\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 5s 767us/step - loss: 0.3481 - accuracy: 0.8449 - val_loss: 0.6855 - val_accuracy: 0.6489\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 5s 769us/step - loss: 0.3130 - accuracy: 0.8637 - val_loss: 0.8016 - val_accuracy: 0.6064\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 5s 768us/step - loss: 0.2708 - accuracy: 0.8821 - val_loss: 0.9457 - val_accuracy: 0.6191\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 5s 759us/step - loss: 0.2414 - accuracy: 0.8959 - val_loss: 0.7799 - val_accuracy: 0.6213\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 5s 768us/step - loss: 0.2056 - accuracy: 0.9161 - val_loss: 0.8369 - val_accuracy: 0.6170\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 5s 767us/step - loss: 0.2002 - accuracy: 0.9180 - val_loss: 0.8023 - val_accuracy: 0.6617\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 5s 766us/step - loss: 0.1742 - accuracy: 0.9321 - val_loss: 0.8543 - val_accuracy: 0.6106\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 5s 769us/step - loss: 0.1469 - accuracy: 0.9423 - val_loss: 0.8954 - val_accuracy: 0.6383\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 5s 770us/step - loss: 0.1420 - accuracy: 0.9459 - val_loss: 0.9300 - val_accuracy: 0.6319\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 5s 770us/step - loss: 0.1335 - accuracy: 0.9466 - val_loss: 1.0058 - val_accuracy: 0.6191\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 5s 768us/step - loss: 0.1229 - accuracy: 0.9529 - val_loss: 0.9927 - val_accuracy: 0.6255\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 5s 767us/step - loss: 0.1053 - accuracy: 0.9620 - val_loss: 1.0734 - val_accuracy: 0.6340\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 5s 760us/step - loss: 0.1061 - accuracy: 0.9583 - val_loss: 0.9198 - val_accuracy: 0.5957\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 5s 765us/step - loss: 0.0991 - accuracy: 0.9611 - val_loss: 0.9734 - val_accuracy: 0.6106\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 5s 765us/step - loss: 0.1007 - accuracy: 0.9613 - val_loss: 1.2108 - val_accuracy: 0.6064\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 5s 766us/step - loss: 0.0949 - accuracy: 0.9674 - val_loss: 1.1284 - val_accuracy: 0.6255\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 5s 767us/step - loss: 0.0888 - accuracy: 0.9666 - val_loss: 1.0040 - val_accuracy: 0.6128\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 5s 764us/step - loss: 0.0854 - accuracy: 0.9666 - val_loss: 1.2053 - val_accuracy: 0.6191\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 5s 765us/step - loss: 0.0806 - accuracy: 0.9716 - val_loss: 1.0243 - val_accuracy: 0.6234\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 5s 766us/step - loss: 0.0675 - accuracy: 0.9760 - val_loss: 1.0137 - val_accuracy: 0.6213\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 5s 766us/step - loss: 0.0684 - accuracy: 0.9744 - val_loss: 1.3384 - val_accuracy: 0.6149\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 5s 767us/step - loss: 0.0681 - accuracy: 0.9751 - val_loss: 1.1365 - val_accuracy: 0.6447\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 5s 768us/step - loss: 0.0764 - accuracy: 0.9724 - val_loss: 1.2625 - val_accuracy: 0.6128\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 5s 766us/step - loss: 0.0719 - accuracy: 0.9736 - val_loss: 1.2082 - val_accuracy: 0.6255\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 5s 769us/step - loss: 0.0659 - accuracy: 0.9756 - val_loss: 1.1208 - val_accuracy: 0.6319\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 6s 817us/step - loss: 0.0608 - accuracy: 0.9794 - val_loss: 1.0534 - val_accuracy: 0.6191\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 6s 803us/step - loss: 0.0641 - accuracy: 0.9763 - val_loss: 1.2620 - val_accuracy: 0.6426\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 5s 762us/step - loss: 0.0609 - accuracy: 0.9786 - val_loss: 1.2096 - val_accuracy: 0.6021\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 5s 759us/step - loss: 0.0572 - accuracy: 0.9789 - val_loss: 1.0276 - val_accuracy: 0.6234\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 6s 789us/step - loss: 0.0595 - accuracy: 0.9787 - val_loss: 1.0838 - val_accuracy: 0.6362\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 6s 875us/step - loss: 0.0631 - accuracy: 0.9770 - val_loss: 1.2118 - val_accuracy: 0.6319\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 5s 765us/step - loss: 0.0464 - accuracy: 0.9834 - val_loss: 1.5531 - val_accuracy: 0.6255\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 5s 769us/step - loss: 0.0451 - accuracy: 0.9836 - val_loss: 1.1391 - val_accuracy: 0.6426\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 5s 780us/step - loss: 0.0535 - accuracy: 0.9809 - val_loss: 1.2966 - val_accuracy: 0.6234\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 5s 765us/step - loss: 0.0465 - accuracy: 0.9837 - val_loss: 1.2023 - val_accuracy: 0.6362\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 6s 791us/step - loss: 0.0614 - accuracy: 0.9767 - val_loss: 1.0839 - val_accuracy: 0.6617\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 5s 781us/step - loss: 0.0381 - accuracy: 0.9864 - val_loss: 1.2847 - val_accuracy: 0.6277\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 5s 761us/step - loss: 0.0400 - accuracy: 0.9869 - val_loss: 1.1510 - val_accuracy: 0.6362\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 5s 783us/step - loss: 0.0417 - accuracy: 0.9839 - val_loss: 1.1221 - val_accuracy: 0.6340\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 5s 782us/step - loss: 0.0458 - accuracy: 0.9841 - val_loss: 1.0079 - val_accuracy: 0.6426\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 5s 767us/step - loss: 0.0458 - accuracy: 0.9827 - val_loss: 1.1932 - val_accuracy: 0.6404\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 5s 759us/step - loss: 0.0479 - accuracy: 0.9829 - val_loss: 1.1597 - val_accuracy: 0.6213\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 5s 760us/step - loss: 0.0479 - accuracy: 0.9827 - val_loss: 1.1042 - val_accuracy: 0.6234\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 5s 761us/step - loss: 0.0426 - accuracy: 0.9864 - val_loss: 1.2659 - val_accuracy: 0.6511\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 5s 758us/step - loss: 0.0399 - accuracy: 0.9860 - val_loss: 1.1176 - val_accuracy: 0.6404\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 5s 763us/step - loss: 0.0463 - accuracy: 0.9831 - val_loss: 1.0808 - val_accuracy: 0.6234\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 5s 764us/step - loss: 0.0396 - accuracy: 0.9860 - val_loss: 1.2567 - val_accuracy: 0.6426\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 5s 769us/step - loss: 0.0432 - accuracy: 0.9849 - val_loss: 1.1132 - val_accuracy: 0.6532\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 5s 774us/step - loss: 0.0381 - accuracy: 0.9856 - val_loss: 1.2750 - val_accuracy: 0.6298\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 5s 770us/step - loss: 0.0383 - accuracy: 0.9856 - val_loss: 1.1157 - val_accuracy: 0.6404\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 5s 770us/step - loss: 0.0310 - accuracy: 0.9890 - val_loss: 1.1657 - val_accuracy: 0.6149\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 5s 772us/step - loss: 0.0336 - accuracy: 0.9881 - val_loss: 1.0038 - val_accuracy: 0.6362\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 5s 771us/step - loss: 0.0364 - accuracy: 0.9870 - val_loss: 1.1124 - val_accuracy: 0.6383\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 5s 768us/step - loss: 0.0321 - accuracy: 0.9896 - val_loss: 1.1302 - val_accuracy: 0.6255\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 5s 772us/step - loss: 0.0348 - accuracy: 0.9861 - val_loss: 1.4450 - val_accuracy: 0.6362\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 5s 785us/step - loss: 0.0345 - accuracy: 0.9879 - val_loss: 1.0102 - val_accuracy: 0.6213\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 5s 773us/step - loss: 0.0353 - accuracy: 0.9876 - val_loss: 1.2167 - val_accuracy: 0.6404\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 5s 772us/step - loss: 0.0373 - accuracy: 0.9863 - val_loss: 1.1125 - val_accuracy: 0.6404\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 5s 774us/step - loss: 0.0286 - accuracy: 0.9901 - val_loss: 1.2066 - val_accuracy: 0.6319\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 5s 780us/step - loss: 0.0310 - accuracy: 0.9881 - val_loss: 1.1661 - val_accuracy: 0.6489\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 5s 774us/step - loss: 0.0329 - accuracy: 0.9884 - val_loss: 1.1100 - val_accuracy: 0.6596\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 6s 842us/step - loss: 0.0329 - accuracy: 0.9890 - val_loss: 1.0632 - val_accuracy: 0.6319\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 6s 786us/step - loss: 0.0270 - accuracy: 0.9906 - val_loss: 1.1204 - val_accuracy: 0.6234\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 5s 762us/step - loss: 0.0338 - accuracy: 0.9867 - val_loss: 1.2927 - val_accuracy: 0.6426\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 6s 790us/step - loss: 0.0363 - accuracy: 0.9873 - val_loss: 1.1167 - val_accuracy: 0.6277\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 5s 770us/step - loss: 0.0334 - accuracy: 0.9884 - val_loss: 1.1513 - val_accuracy: 0.6404\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 5s 770us/step - loss: 0.0364 - accuracy: 0.9866 - val_loss: 0.9681 - val_accuracy: 0.6447\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 5s 775us/step - loss: 0.0341 - accuracy: 0.9881 - val_loss: 1.1601 - val_accuracy: 0.6489\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 5s 771us/step - loss: 0.0331 - accuracy: 0.9890 - val_loss: 1.1241 - val_accuracy: 0.6426\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 6s 809us/step - loss: 0.0319 - accuracy: 0.9897 - val_loss: 1.3368 - val_accuracy: 0.6426\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 6s 843us/step - loss: 0.0229 - accuracy: 0.9907 - val_loss: 0.8892 - val_accuracy: 0.6617\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 5s 780us/step - loss: 0.0334 - accuracy: 0.9886 - val_loss: 1.1719 - val_accuracy: 0.6617\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 5s 782us/step - loss: 0.0234 - accuracy: 0.9916 - val_loss: 1.3280 - val_accuracy: 0.6511\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 5s 773us/step - loss: 0.0288 - accuracy: 0.9900 - val_loss: 1.0721 - val_accuracy: 0.6468\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 5s 775us/step - loss: 0.0246 - accuracy: 0.9909 - val_loss: 1.0739 - val_accuracy: 0.6553\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 5s 773us/step - loss: 0.0224 - accuracy: 0.9920 - val_loss: 1.0076 - val_accuracy: 0.6574\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 5s 784us/step - loss: 0.0273 - accuracy: 0.9904 - val_loss: 1.1825 - val_accuracy: 0.6532\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 5s 776us/step - loss: 0.0290 - accuracy: 0.9899 - val_loss: 1.0832 - val_accuracy: 0.6277\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 5s 775us/step - loss: 0.0271 - accuracy: 0.9904 - val_loss: 1.2587 - val_accuracy: 0.6596\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 6s 791us/step - loss: 0.0259 - accuracy: 0.9896 - val_loss: 0.9699 - val_accuracy: 0.6468\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 5s 772us/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 0.9042 - val_accuracy: 0.6468\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 5s 766us/step - loss: 0.0236 - accuracy: 0.9924 - val_loss: 0.9923 - val_accuracy: 0.6532\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 5s 777us/step - loss: 0.0248 - accuracy: 0.9911 - val_loss: 1.1705 - val_accuracy: 0.6532\n",
      "CNN Error: 34.68%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, save_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import loader4\n",
    "\n",
    "batch_size = 28\n",
    "num_classes = 2\n",
    "epochs = 100\n",
    " \n",
    "train_image='E:\\\\data11\\\\train_resize_64\\\\'\n",
    "train_label= 'E:\\\\data11\\\\train_label.csv'\n",
    "test_image='E:\\\\data11\\\\test_resize_64\\\\'\n",
    "test_label='E:\\\\data11\\\\test_label.csv'\n",
    "\n",
    "x_train = loader4.image_load(train_image)\n",
    "y_train = loader4.label_load(train_label)\n",
    "x_test = loader4.image_load(test_image)\n",
    "y_test = loader4.label_load(test_label)      \n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(x_train.shape[1:])\n",
    "\n",
    "#(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "# One hot Encoding\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    " \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    " \n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    " \n",
    "hist = model.fit(x_train, y_train, validation_data=(x_test, y_test), nb_epoch=epochs, batch_size=batch_size, verbose=1)\n",
    " \n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\n",
    " \n",
    "save_model(model, \"E:\\data11\\\\models\\\\result_64.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf2.0-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
