{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ Image Files resize (32x32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  cv2\n",
    "import  os \n",
    "import  numpy  as np\n",
    "\n",
    "path = \"E:\\\\data11\\\\original\"\n",
    "\n",
    "file_list = os.listdir(path)\n",
    "    \n",
    "for k in file_list:\n",
    "    img = cv2.imread(path + '\\\\' + k)\n",
    "    width, height = img.shape[:2]\n",
    "    resize_img = cv2.resize(img, (32 , 32), interpolation=cv2.INTER_CUBIC)\n",
    "    cv2.imwrite('E:\\\\data11\\\\resize\\\\' + k, resize_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ Setting\n",
    "\n",
    "#### ▶ Train_data (1 ~ 7000) :  7000개\n",
    "\n",
    "#### ▶ Test_data (7001 ~ 7470) : 470개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ Create Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ● Change 2 dimension array to 1 dimension array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "path1 = 'E:\\\\data11\\\\xray_labels.csv'\n",
    "file = open(path1)\n",
    "\n",
    "labeldata = csv.reader(file)\n",
    "labellist = []\n",
    "\n",
    "for  i   in  labeldata:\n",
    "    labellist.append(i)\n",
    "\n",
    "labellist2 = sum(labellist,[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ● Change 'normal' = 1 , 'patient' = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = 'E:\\\\data11\\\\xray_labels2.csv'\n",
    "file2 = open(path2, 'w')\n",
    "\n",
    "# normal = 1 , patient = 0\n",
    "\n",
    "for  i  in  labellist2:\n",
    "    if i == 'patient':\n",
    "        file2.write( str(0) + '\\n' )\n",
    "    else:\n",
    "        file2.write( str(1) + '\\n' )\n",
    "        \n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ● Save Train Labels and Test Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train labels\n",
    "\n",
    "path = 'E:\\\\data11\\\\xray_labels2.csv'\n",
    "file = open(path)\n",
    "\n",
    "labeldata = csv.reader(file)\n",
    "labellist = []\n",
    "\n",
    "for  i   in  labeldata:\n",
    "    labellist.append(i)\n",
    "\n",
    "labellist2 = sum(labellist,[]) # sum 함수의 default 값은 0이므로 []로 바꾸어서 리스트 합침.\n",
    "\n",
    "# print(labellist)\n",
    "\n",
    "\n",
    "path2 = 'E:\\\\data11\\\\train_label.csv'\n",
    "file2 = open(path2, 'w')\n",
    "\n",
    "for  i  in  range(0,7000):\n",
    "    file2.write( str(labellist2[i]) + '\\n' )\n",
    "    \n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save test labels\n",
    "\n",
    "path = 'E:\\\\data11\\\\xray_labels2.csv'\n",
    "file = open(path)\n",
    "\n",
    "labeldata = csv.reader(file)\n",
    "labellist = []\n",
    "\n",
    "for  i   in  labeldata:\n",
    "    labellist.append(i)\n",
    "\n",
    "labellist2 = sum(labellist,[]) # sum 함수의 default 값은 0이므로 []로 바꾸어서 리스트 합침.\n",
    "\n",
    "# print(labellist)\n",
    "\n",
    "\n",
    "path2 = 'E:\\\\data11\\\\test_label.csv'\n",
    "file2 = open(path2, 'w')\n",
    "\n",
    "for  i  in  range(7000,7470):\n",
    "    file2.write( str(labellist2[i]) + '\\n' )\n",
    "    \n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ Create loader4.py \n",
    "\n",
    " ■ image_load  \n",
    " ■ next_batch  \n",
    " ■ shuffle_batch  \n",
    " ■ label_load  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import   csv\n",
    "import  os\n",
    "import  re\n",
    "import  cv2\n",
    "import  random\n",
    "import  numpy  as  np\n",
    "\n",
    "def  image_load(path):\n",
    "    file_list = os.listdir(path)\n",
    "    file_name = []\n",
    "    for  i  in  file_list:\n",
    "        a = int(  re.sub('[^0-9]', '', i )  ) # 숫자가 아닌것은 '' 로 처리 \n",
    "        file_name.append(a) \n",
    "    file_name.sort()\n",
    "\n",
    "    file_res = [] \n",
    "    for  j  in   file_name:\n",
    "        file_res.append('%s\\\\%d.png' %(path,j)  )\n",
    "\n",
    "    image = []\n",
    "    for  k  in  file_res:\n",
    "        img = cv2.imread(k)\n",
    "        image.append(img)\n",
    "\n",
    "    return  np.array(image)\n",
    "\n",
    "def  label_load( path ):\n",
    "    file = open(path)\n",
    "    labeldata = csv.reader(file)\n",
    "    labellist = []\n",
    "    for  i   in  labeldata:\n",
    "        labellist.append(i)\n",
    "\n",
    "    label = np.array(labellist)\n",
    "    label = label.astype(int)  # 숫자로 변환 \n",
    "    label = np.eye(2)[label]\n",
    "    label = label.reshape(-1,2) \n",
    "    return  label\n",
    "\n",
    "\n",
    "def  shuffle_batch( data_list, label ):\n",
    "    x = np.arange( len( data_list) )\n",
    "    random.shuffle(x)\n",
    "    data_list2 = data_list[x]\n",
    "    label2 = label[x]\n",
    "    return   data_list2, label2 \n",
    "\n",
    "\n",
    "def  next_batch( data1, data2, init,  fina ):\n",
    "    return  data1[ init : fina ],  data2[init : fina] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ● Check train_data and test_data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 32, 32, 3)\n",
      "(7000, 2)\n",
      "(470, 32, 32, 3)\n",
      "(470, 2)\n"
     ]
    }
   ],
   "source": [
    "import loader4\n",
    "\n",
    "train_image='E:\\\\data11\\\\train_resize\\\\'\n",
    "train_label= 'E:\\\\data11\\\\train_label.csv'\n",
    "test_image='E:\\\\data11\\\\test_resize\\\\'\n",
    "test_label='E:\\\\data11\\\\test_label.csv'\n",
    "\n",
    "print(loader4.image_load(train_image).shape)\n",
    "print(loader4.label_load(train_label).shape)\n",
    "print(loader4.image_load(test_image).shape)\n",
    "print(loader4.label_load(test_label).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ Train start !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 32, 32, 3)\n",
      "(7000, 2)\n",
      "(470, 32, 32, 3)\n",
      "(470, 2)\n",
      "(32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\ipykernel_launcher.py:74: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 470 samples\n",
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 4s 559us/step - loss: 0.8226 - accuracy: 0.5937 - val_loss: 0.6686 - val_accuracy: 0.6149\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 3s 379us/step - loss: 0.6839 - accuracy: 0.6143 - val_loss: 0.6637 - val_accuracy: 0.6085\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 3s 385us/step - loss: 0.6481 - accuracy: 0.6410 - val_loss: 0.6345 - val_accuracy: 0.6277\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 3s 389us/step - loss: 0.6367 - accuracy: 0.6406 - val_loss: 0.6656 - val_accuracy: 0.6340\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 3s 387us/step - loss: 0.6219 - accuracy: 0.6520 - val_loss: 0.6433 - val_accuracy: 0.6170\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 3s 434us/step - loss: 0.6184 - accuracy: 0.6591 - val_loss: 0.6309 - val_accuracy: 0.6404\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 3s 415us/step - loss: 0.6231 - accuracy: 0.6530 - val_loss: 0.6578 - val_accuracy: 0.6128\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 3s 396us/step - loss: 0.6064 - accuracy: 0.6744 - val_loss: 0.6787 - val_accuracy: 0.6170\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 3s 389us/step - loss: 0.6036 - accuracy: 0.6669 - val_loss: 0.6800 - val_accuracy: 0.6128\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.5995 - accuracy: 0.6780 - val_loss: 0.6276 - val_accuracy: 0.6532\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 3s 389us/step - loss: 0.5841 - accuracy: 0.6873 - val_loss: 0.6379 - val_accuracy: 0.6298\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 3s 384us/step - loss: 0.5838 - accuracy: 0.6864 - val_loss: 0.6243 - val_accuracy: 0.6532\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 3s 383us/step - loss: 0.5659 - accuracy: 0.7011 - val_loss: 0.6383 - val_accuracy: 0.6532\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.5698 - accuracy: 0.7034 - val_loss: 0.6201 - val_accuracy: 0.6532\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 3s 395us/step - loss: 0.5499 - accuracy: 0.7136 - val_loss: 0.6249 - val_accuracy: 0.6532\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 3s 388us/step - loss: 0.5415 - accuracy: 0.7253 - val_loss: 0.6065 - val_accuracy: 0.6745\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 3s 384us/step - loss: 0.5183 - accuracy: 0.7404 - val_loss: 0.6149 - val_accuracy: 0.6809\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 3s 391us/step - loss: 0.5133 - accuracy: 0.7437 - val_loss: 0.6255 - val_accuracy: 0.6532\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 3s 389us/step - loss: 0.4929 - accuracy: 0.7563 - val_loss: 0.6071 - val_accuracy: 0.6681\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.4700 - accuracy: 0.7684 - val_loss: 0.6383 - val_accuracy: 0.6681\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 3s 390us/step - loss: 0.4576 - accuracy: 0.7801 - val_loss: 0.6300 - val_accuracy: 0.6489\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.4319 - accuracy: 0.7946 - val_loss: 0.6305 - val_accuracy: 0.6766\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 3s 385us/step - loss: 0.4113 - accuracy: 0.8037 - val_loss: 0.7187 - val_accuracy: 0.6596\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 3s 384us/step - loss: 0.3884 - accuracy: 0.8236 - val_loss: 0.7054 - val_accuracy: 0.6660\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 3s 387us/step - loss: 0.3707 - accuracy: 0.8344 - val_loss: 0.6634 - val_accuracy: 0.6681\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.3510 - accuracy: 0.8413 - val_loss: 0.7555 - val_accuracy: 0.6255\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 3s 388us/step - loss: 0.3330 - accuracy: 0.8536 - val_loss: 0.7682 - val_accuracy: 0.6511\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 3s 391us/step - loss: 0.3195 - accuracy: 0.8619 - val_loss: 0.7790 - val_accuracy: 0.6404\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 3s 395us/step - loss: 0.2946 - accuracy: 0.8750 - val_loss: 0.7101 - val_accuracy: 0.6830\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 3s 392us/step - loss: 0.2845 - accuracy: 0.8769 - val_loss: 0.8336 - val_accuracy: 0.6596\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 3s 385us/step - loss: 0.2584 - accuracy: 0.8937 - val_loss: 0.7645 - val_accuracy: 0.6745\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 3s 384us/step - loss: 0.2407 - accuracy: 0.8990 - val_loss: 0.8706 - val_accuracy: 0.6617\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 3s 391us/step - loss: 0.2422 - accuracy: 0.8964 - val_loss: 0.9678 - val_accuracy: 0.6787\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.2261 - accuracy: 0.9057 - val_loss: 0.8238 - val_accuracy: 0.6702\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.2171 - accuracy: 0.9144 - val_loss: 0.8292 - val_accuracy: 0.6553\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 3s 387us/step - loss: 0.2137 - accuracy: 0.9127 - val_loss: 0.7316 - val_accuracy: 0.6532\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.2082 - accuracy: 0.9129 - val_loss: 0.8605 - val_accuracy: 0.6340\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 3s 388us/step - loss: 0.1919 - accuracy: 0.9256 - val_loss: 0.9730 - val_accuracy: 0.6681\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 3s 385us/step - loss: 0.1879 - accuracy: 0.9236 - val_loss: 0.8448 - val_accuracy: 0.6298\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.1707 - accuracy: 0.9314 - val_loss: 0.8145 - val_accuracy: 0.6596\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 3s 390us/step - loss: 0.1654 - accuracy: 0.9326 - val_loss: 0.8625 - val_accuracy: 0.6532\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 3s 387us/step - loss: 0.1742 - accuracy: 0.9351 - val_loss: 0.8127 - val_accuracy: 0.6617\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 3s 388us/step - loss: 0.1514 - accuracy: 0.9420 - val_loss: 0.9074 - val_accuracy: 0.6404\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 3s 387us/step - loss: 0.1583 - accuracy: 0.9377 - val_loss: 0.8992 - val_accuracy: 0.6404\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 3s 385us/step - loss: 0.1542 - accuracy: 0.9356 - val_loss: 1.0030 - val_accuracy: 0.6766\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 3s 385us/step - loss: 0.1448 - accuracy: 0.9440 - val_loss: 0.9941 - val_accuracy: 0.6617\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 3s 384us/step - loss: 0.1432 - accuracy: 0.9436 - val_loss: 0.9021 - val_accuracy: 0.6681\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 3s 390us/step - loss: 0.1371 - accuracy: 0.9464 - val_loss: 0.9338 - val_accuracy: 0.6766\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 3s 384us/step - loss: 0.1264 - accuracy: 0.9521 - val_loss: 0.9437 - val_accuracy: 0.6447\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.1282 - accuracy: 0.9526 - val_loss: 0.9723 - val_accuracy: 0.6553\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 3s 389us/step - loss: 0.1202 - accuracy: 0.9543 - val_loss: 1.0707 - val_accuracy: 0.6681\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.1239 - accuracy: 0.9509 - val_loss: 0.8737 - val_accuracy: 0.6787\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 3s 388us/step - loss: 0.1277 - accuracy: 0.9523 - val_loss: 0.9257 - val_accuracy: 0.6766\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 3s 384us/step - loss: 0.1167 - accuracy: 0.9550 - val_loss: 0.9009 - val_accuracy: 0.6617\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 3s 385us/step - loss: 0.1282 - accuracy: 0.9474 - val_loss: 0.9621 - val_accuracy: 0.6660\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 3s 387us/step - loss: 0.1155 - accuracy: 0.9550 - val_loss: 0.9637 - val_accuracy: 0.6638\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 3s 398us/step - loss: 0.1023 - accuracy: 0.9593 - val_loss: 0.9895 - val_accuracy: 0.6660\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 3s 380us/step - loss: 0.0937 - accuracy: 0.9659 - val_loss: 0.9694 - val_accuracy: 0.6702\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 3s 384us/step - loss: 0.1145 - accuracy: 0.9581 - val_loss: 1.0279 - val_accuracy: 0.6787\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 3s 383us/step - loss: 0.0989 - accuracy: 0.9597 - val_loss: 0.9356 - val_accuracy: 0.6723\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - ETA: 0s - loss: 0.1015 - accuracy: 0.96 - 3s 380us/step - loss: 0.1016 - accuracy: 0.9604 - val_loss: 1.0448 - val_accuracy: 0.6638\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 3s 387us/step - loss: 0.1001 - accuracy: 0.9604 - val_loss: 1.0526 - val_accuracy: 0.6574\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.0960 - accuracy: 0.9639 - val_loss: 1.0406 - val_accuracy: 0.6553\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 3s 382us/step - loss: 0.0879 - accuracy: 0.9664 - val_loss: 1.0280 - val_accuracy: 0.6830\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 3s 381us/step - loss: 0.0918 - accuracy: 0.9663 - val_loss: 1.0275 - val_accuracy: 0.6681\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 3s 385us/step - loss: 0.1002 - accuracy: 0.9611 - val_loss: 1.0335 - val_accuracy: 0.6745\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 3s 381us/step - loss: 0.1040 - accuracy: 0.9624 - val_loss: 0.9618 - val_accuracy: 0.6915\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 3s 383us/step - loss: 0.0872 - accuracy: 0.9670 - val_loss: 1.0011 - val_accuracy: 0.6851\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 3s 384us/step - loss: 0.0846 - accuracy: 0.9691 - val_loss: 0.9805 - val_accuracy: 0.6723\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 3s 392us/step - loss: 0.0938 - accuracy: 0.9620 - val_loss: 0.9936 - val_accuracy: 0.6702\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 3s 388us/step - loss: 0.0972 - accuracy: 0.9644 - val_loss: 1.0120 - val_accuracy: 0.6574\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.0821 - accuracy: 0.9696 - val_loss: 1.1142 - val_accuracy: 0.6723\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.0809 - accuracy: 0.9700 - val_loss: 0.9525 - val_accuracy: 0.6404\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 3s 385us/step - loss: 0.0802 - accuracy: 0.9694 - val_loss: 1.0416 - val_accuracy: 0.6660\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 3s 383us/step - loss: 0.0753 - accuracy: 0.9737 - val_loss: 1.0767 - val_accuracy: 0.6617\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.0832 - accuracy: 0.9697 - val_loss: 0.9684 - val_accuracy: 0.6723\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 3s 388us/step - loss: 0.0687 - accuracy: 0.9726 - val_loss: 1.0823 - val_accuracy: 0.6596\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 3s 384us/step - loss: 0.0754 - accuracy: 0.9717 - val_loss: 1.0915 - val_accuracy: 0.6511\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 3s 388us/step - loss: 0.0791 - accuracy: 0.9666 - val_loss: 1.0858 - val_accuracy: 0.6809\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 3s 385us/step - loss: 0.0835 - accuracy: 0.9681 - val_loss: 0.9971 - val_accuracy: 0.6660\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.0814 - accuracy: 0.9706 - val_loss: 0.9607 - val_accuracy: 0.6681\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 3s 382us/step - loss: 0.0878 - accuracy: 0.9674 - val_loss: 1.0837 - val_accuracy: 0.6957\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.0624 - accuracy: 0.9767 - val_loss: 1.0536 - val_accuracy: 0.6660\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 3s 389us/step - loss: 0.0766 - accuracy: 0.9701 - val_loss: 0.9705 - val_accuracy: 0.6702\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 3s 395us/step - loss: 0.0706 - accuracy: 0.9736 - val_loss: 0.9056 - val_accuracy: 0.6957\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 3s 406us/step - loss: 0.0708 - accuracy: 0.9756 - val_loss: 1.0535 - val_accuracy: 0.6723\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 3s 390us/step - loss: 0.0729 - accuracy: 0.9741 - val_loss: 1.0761 - val_accuracy: 0.6766\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 3s 387us/step - loss: 0.0749 - accuracy: 0.9761 - val_loss: 1.2102 - val_accuracy: 0.6723\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 3s 393us/step - loss: 0.0745 - accuracy: 0.9719 - val_loss: 0.9831 - val_accuracy: 0.6553\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 3s 401us/step - loss: 0.0653 - accuracy: 0.9743 - val_loss: 1.0932 - val_accuracy: 0.6638\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 3s 430us/step - loss: 0.0664 - accuracy: 0.9750 - val_loss: 1.0105 - val_accuracy: 0.6745\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 3s 403us/step - loss: 0.0609 - accuracy: 0.9789 - val_loss: 0.9647 - val_accuracy: 0.6681\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 3s 400us/step - loss: 0.0638 - accuracy: 0.9773 - val_loss: 1.0506 - val_accuracy: 0.6894\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 3s 390us/step - loss: 0.0569 - accuracy: 0.9793 - val_loss: 1.0532 - val_accuracy: 0.6574\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 3s 387us/step - loss: 0.0627 - accuracy: 0.9759 - val_loss: 1.0961 - val_accuracy: 0.6957\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 3s 384us/step - loss: 0.0748 - accuracy: 0.9730 - val_loss: 0.9761 - val_accuracy: 0.7000\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 3s 384us/step - loss: 0.0730 - accuracy: 0.9729 - val_loss: 1.0233 - val_accuracy: 0.6809\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 3s 379us/step - loss: 0.0681 - accuracy: 0.9759 - val_loss: 1.0244 - val_accuracy: 0.6979\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 3s 395us/step - loss: 0.0665 - accuracy: 0.9753 - val_loss: 1.0286 - val_accuracy: 0.6766\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 3s 401us/step - loss: 0.0533 - accuracy: 0.9820 - val_loss: 1.1389 - val_accuracy: 0.6702\n",
      "CNN Error: 32.98%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, save_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import loader4\n",
    "\n",
    "batch_size = 28\n",
    "num_classes = 2\n",
    "epochs = 100\n",
    " \n",
    "train_image='E:\\\\data11\\\\train_resize\\\\'\n",
    "train_label= 'E:\\\\data11\\\\train_label.csv'\n",
    "test_image='E:\\\\data11\\\\test_resize\\\\'\n",
    "test_label='E:\\\\data11\\\\test_label.csv'\n",
    "\n",
    "\n",
    "x_train = loader4.image_load(train_image)\n",
    "y_train = loader4.label_load(train_label)\n",
    "x_test = loader4.image_load(test_image)\n",
    "y_test = loader4.label_load(test_label)      \n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(x_train.shape[1:])\n",
    "\n",
    "#(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "# One hot Encoding\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    " \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    " \n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    " \n",
    "hist = model.fit(x_train, y_train, validation_data=(x_test, y_test), nb_epoch=epochs, batch_size=batch_size, verbose=1)\n",
    " \n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\n",
    " \n",
    "save_model(model, \"E:\\data11\\\\models\\\\result2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ Vgg16.ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 32, 32, 3)\n",
      "(7000, 2)\n",
      "(470, 32, 32, 3)\n",
      "(470, 2)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 8194      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 33,655,106\n",
      "Trainable params: 33,630,274\n",
      "Non-trainable params: 24,832\n",
      "_________________________________________________________________\n",
      "Train on 7000 samples, validate on 470 samples\n",
      "Epoch 1/50\n",
      "7000/7000 [==============================] - 17s 2ms/step - loss: 0.9980 - accuracy: 0.5743 - val_loss: 3.7403 - val_accuracy: 0.5170\n",
      "Epoch 2/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.8150 - accuracy: 0.5991 - val_loss: 2.3575 - val_accuracy: 0.5426\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.8346 - accuracy: 0.5870 - val_loss: 1.4160 - val_accuracy: 0.6043\n",
      "Epoch 4/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7780 - accuracy: 0.6093 - val_loss: 1.1063 - val_accuracy: 0.6021\n",
      "Epoch 5/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7849 - accuracy: 0.6119 - val_loss: 0.7338 - val_accuracy: 0.6043\n",
      "Epoch 6/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7709 - accuracy: 0.6154 - val_loss: 0.8298 - val_accuracy: 0.6043\n",
      "Epoch 7/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7983 - accuracy: 0.6030 - val_loss: 4.7186 - val_accuracy: 0.4660\n",
      "Epoch 8/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7947 - accuracy: 0.6077 - val_loss: 3.0291 - val_accuracy: 0.6043\n",
      "Epoch 9/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7692 - accuracy: 0.6067 - val_loss: 0.7080 - val_accuracy: 0.5362s - los\n",
      "Epoch 10/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7847 - accuracy: 0.5897 - val_loss: 0.6882 - val_accuracy: 0.6043\n",
      "Epoch 11/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7882 - accuracy: 0.6017 - val_loss: 0.8878 - val_accuracy: 0.6043\n",
      "Epoch 12/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7882 - accuracy: 0.6090 - val_loss: 0.6747 - val_accuracy: 0.5936\n",
      "Epoch 13/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7741 - accuracy: 0.6104 - val_loss: 0.7172 - val_accuracy: 0.6043\n",
      "Epoch 14/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7822 - accuracy: 0.6110 - val_loss: 0.9064 - val_accuracy: 0.6000\n",
      "Epoch 15/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7727 - accuracy: 0.6123 - val_loss: 1.1906 - val_accuracy: 0.6000\n",
      "Epoch 16/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7515 - accuracy: 0.6229 - val_loss: 0.7049 - val_accuracy: 0.5957\n",
      "Epoch 17/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7652 - accuracy: 0.6106 - val_loss: 0.8294 - val_accuracy: 0.5830\n",
      "Epoch 18/50\n",
      "7000/7000 [==============================] - 13s 2ms/step - loss: 0.7741 - accuracy: 0.6183 - val_loss: 0.6779 - val_accuracy: 0.5957\n",
      "Epoch 19/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7712 - accuracy: 0.6163 - val_loss: 0.8948 - val_accuracy: 0.6043\n",
      "Epoch 20/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7728 - accuracy: 0.6070 - val_loss: 1.0608 - val_accuracy: 0.6043\n",
      "Epoch 21/50\n",
      "7000/7000 [==============================] - 13s 2ms/step - loss: 0.7727 - accuracy: 0.6133 - val_loss: 4.3698 - val_accuracy: 0.5064\n",
      "Epoch 22/50\n",
      "7000/7000 [==============================] - 13s 2ms/step - loss: 0.8061 - accuracy: 0.6039 - val_loss: 0.7335 - val_accuracy: 0.5766\n",
      "Epoch 23/50\n",
      "7000/7000 [==============================] - 13s 2ms/step - loss: 0.8128 - accuracy: 0.5957 - val_loss: 0.6745 - val_accuracy: 0.6043\n",
      "Epoch 24/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7889 - accuracy: 0.6106 - val_loss: 7.4729 - val_accuracy: 0.6043\n",
      "Epoch 25/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7725 - accuracy: 0.6126 - val_loss: 0.7378 - val_accuracy: 0.5894\n",
      "Epoch 26/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7731 - accuracy: 0.6191 - val_loss: 0.9547 - val_accuracy: 0.5660\n",
      "Epoch 27/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7851 - accuracy: 0.6179 - val_loss: 0.6869 - val_accuracy: 0.6021\n",
      "Epoch 28/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7746 - accuracy: 0.6107 - val_loss: 0.6976 - val_accuracy: 0.6043\n",
      "Epoch 29/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7780 - accuracy: 0.6151 - val_loss: 1.9482 - val_accuracy: 0.5723\n",
      "Epoch 30/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7752 - accuracy: 0.6239 - val_loss: 1.2786 - val_accuracy: 0.6043\n",
      "Epoch 31/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7730 - accuracy: 0.6213 - val_loss: 0.6799 - val_accuracy: 0.6043\n",
      "Epoch 32/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7493 - accuracy: 0.6227 - val_loss: 1.2393 - val_accuracy: 0.5766\n",
      "Epoch 33/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7508 - accuracy: 0.6237 - val_loss: 0.8801 - val_accuracy: 0.5532\n",
      "Epoch 34/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7437 - accuracy: 0.6223 - val_loss: 0.6999 - val_accuracy: 0.5872\n",
      "Epoch 35/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.8021 - accuracy: 0.6096 - val_loss: 0.6780 - val_accuracy: 0.6043\n",
      "Epoch 36/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7986 - accuracy: 0.6203 - val_loss: 0.9247 - val_accuracy: 0.5894\n",
      "Epoch 37/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7698 - accuracy: 0.6230 - val_loss: 0.8387 - val_accuracy: 0.6043\n",
      "Epoch 38/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.8270 - accuracy: 0.5944 - val_loss: 3.7086 - val_accuracy: 0.5511\n",
      "Epoch 39/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.8163 - accuracy: 0.6127 - val_loss: 1.0901 - val_accuracy: 0.5872\n",
      "Epoch 40/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7909 - accuracy: 0.6226 - val_loss: 0.7099 - val_accuracy: 0.6043\n",
      "Epoch 41/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7667 - accuracy: 0.6201 - val_loss: 0.6756 - val_accuracy: 0.6043\n",
      "Epoch 42/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7651 - accuracy: 0.6210 - val_loss: 0.7587 - val_accuracy: 0.5979\n",
      "Epoch 43/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7719 - accuracy: 0.6097 - val_loss: 4.8059 - val_accuracy: 0.6043\n",
      "Epoch 44/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7810 - accuracy: 0.6170 - val_loss: 0.7292 - val_accuracy: 0.6043\n",
      "Epoch 45/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7682 - accuracy: 0.6266 - val_loss: 0.7559 - val_accuracy: 0.6043\n",
      "Epoch 46/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7960 - accuracy: 0.6231 - val_loss: 0.7533 - val_accuracy: 0.5553\n",
      "Epoch 47/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7637 - accuracy: 0.6203 - val_loss: 1.9018 - val_accuracy: 0.6043\n",
      "Epoch 48/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7592 - accuracy: 0.6287 - val_loss: 1.1747 - val_accuracy: 0.6043\n",
      "Epoch 49/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7714 - accuracy: 0.6201 - val_loss: 1.1430 - val_accuracy: 0.6043\n",
      "Epoch 50/50\n",
      "7000/7000 [==============================] - 12s 2ms/step - loss: 0.7602 - accuracy: 0.6294 - val_loss: 0.8179 - val_accuracy: 0.6043\n",
      "470/470 [==============================] - 0s 342us/step\n",
      "['정상']\n",
      "['정상']\n"
     ]
    }
   ],
   "source": [
    "import os, cv2, random\n",
    "\n",
    "# 필요한 라이브러리 import 하는 코드 \n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Input, Flatten, Dense, Conv2D, BatchNormalization, LeakyReLU, Dropout, Activation, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K   # 백엔드가  텐서 플로우로 되어있어서 \n",
    "                                     # 텐서 플로우 명령어 필요할 때 tf 대신에 \n",
    "                                     # k 를 쓰겠다라는 의미 \n",
    "\n",
    "import loader4\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "train_image='E:\\\\data11\\\\train_resize\\\\'\n",
    "train_label= 'E:\\\\data11\\\\train_label.csv'\n",
    "test_image='E:\\\\data11\\\\test_resize\\\\'\n",
    "test_label='E:\\\\data11\\\\test_label.csv'\n",
    "\n",
    "print(loader4.image_load(train_image).shape)\n",
    "print(loader4.label_load(train_label).shape)\n",
    "print(loader4.image_load(test_image).shape)\n",
    "print(loader4.label_load(test_label).shape)\n",
    "\n",
    "x_train = loader4.image_load(train_image)\n",
    "y_train = loader4.label_load(train_label)\n",
    "x_test = loader4.image_load(test_image)\n",
    "y_test = loader4.label_load(test_label)\n",
    "\n",
    "# 모델 만들기\n",
    "input_layer = Input((32,32,3))\n",
    "\n",
    "x = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same')(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size = 2, strides = 2)(x)\n",
    "\n",
    "x = Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size = 2, strides = 2)(x)\n",
    "\n",
    "x = Conv2D(filters = 256, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters = 256, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters = 256, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size = 2, strides = 2)(x)\n",
    "\n",
    "x = Conv2D(filters = 512, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters = 512, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters = 512, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size = 2, strides = 2)(x)\n",
    "\n",
    "x = Conv2D(filters = 512, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters = 512, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters = 512, kernel_size = 3, strides = 1, padding = 'same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size = 2, strides = 2)(x)\n",
    "\n",
    "# 완전 연결 계층\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(4096)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate = 0.5)(x)\n",
    "\n",
    "x = Dense(4096)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(rate = 0.5)(x)\n",
    "\n",
    "x = Dense(NUM_CLASSES)(x)\n",
    "output_layer = Activation('softmax')(x)\n",
    "\n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "# convolution 층 5개, 완전 연결계층 3개인 8층 신경망\n",
    "model.summary()\n",
    "\n",
    "# 모델 훈련\n",
    "\n",
    "model_exists = False\n",
    "\n",
    "\n",
    "if model_exists:\n",
    "    \n",
    "    \n",
    "    model.load_weights('E:\\data11\\\\models\\\\resultvgg16.h5')\n",
    "    \n",
    "    CLASSES = np.array(['정상', '비정상' ]) \n",
    "    preds = model.predict( x_test[1:2] )   \n",
    "    preds_value = CLASSES[ np.argmax( preds, axis= -1 ) ] \n",
    "    actual_value = CLASSES[ np.argmax( y_test [1:2], axis = -1) ] \n",
    "    print ( preds_value)\n",
    "    print ( actual_value)\n",
    "    \n",
    "else:\n",
    "        \n",
    "    opt = Adam(lr=0.0005)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(x_train\n",
    "              , y_train\n",
    "              , batch_size=28\n",
    "              , epochs=50\n",
    "              , shuffle=True\n",
    "               , validation_data=(x_test,y_test) )\n",
    "    \n",
    "    \n",
    "    model.save_weights('E:\\data11\\\\models\\\\resultvgg16.h5')\n",
    "    \n",
    "    model.evaluate(x_test, y_test, batch_size=28)\n",
    "    \n",
    "    CLASSES = np.array(['정상', '비정상' ]) \n",
    "    preds = model.predict( x_test[1:2] )   \n",
    "    preds_value = CLASSES[ np.argmax( preds, axis= -1 ) ] \n",
    "    actual_value = CLASSES[ np.argmax( y_test[1:2], axis = -1) ] \n",
    "    print ( preds_value)\n",
    "    print ( actual_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf2.0-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
