{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ Image Files resize (32x32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  cv2\n",
    "import  os \n",
    "import  numpy  as np\n",
    "\n",
    "path = \"E:\\\\data11\\\\original\"\n",
    "\n",
    "file_list = os.listdir(path)\n",
    "    \n",
    "for k in file_list:\n",
    "    img = cv2.imread(path + '\\\\' + k)\n",
    "    width, height = img.shape[:2]\n",
    "    resize_img = cv2.resize(img, (32 , 32), interpolation=cv2.INTER_CUBIC)\n",
    "    cv2.imwrite('E:\\\\data11\\\\resize\\\\' + k, resize_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ Setting\n",
    "\n",
    "#### ▶ Train_data (1 ~ 7000) :  7000개\n",
    "\n",
    "#### ▶ Test_data (7001 ~ 7470) : 470개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ Create Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ● Change 2 dimension array to 1 dimension array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "path1 = 'E:\\\\data11\\\\xray_labels.csv'\n",
    "file = open(path1)\n",
    "\n",
    "labeldata = csv.reader(file)\n",
    "labellist = []\n",
    "\n",
    "for  i   in  labeldata:\n",
    "    labellist.append(i)\n",
    "\n",
    "labellist2 = sum(labellist,[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ● Change 'normal' = 1 , 'patient' = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = 'E:\\\\data11\\\\xray_labels2.csv'\n",
    "file2 = open(path2, 'w')\n",
    "\n",
    "# normal = 1 , patient = 0\n",
    "\n",
    "for  i  in  labellist2:\n",
    "    if i == 'patient':\n",
    "        file2.write( str(0) + '\\n' )\n",
    "    else:\n",
    "        file2.write( str(1) + '\\n' )\n",
    "        \n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ● Save Train Labels and Test Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train labels\n",
    "\n",
    "path = 'E:\\\\data11\\\\xray_labels2.csv'\n",
    "file = open(path)\n",
    "\n",
    "labeldata = csv.reader(file)\n",
    "labellist = []\n",
    "\n",
    "for  i   in  labeldata:\n",
    "    labellist.append(i)\n",
    "\n",
    "labellist2 = sum(labellist,[]) # sum 함수의 default 값은 0이므로 []로 바꾸어서 리스트 합침.\n",
    "\n",
    "# print(labellist)\n",
    "\n",
    "\n",
    "path2 = 'E:\\\\data11\\\\train_label.csv'\n",
    "file2 = open(path2, 'w')\n",
    "\n",
    "for  i  in  range(0,7000):\n",
    "    file2.write( str(labellist2[i]) + '\\n' )\n",
    "    \n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save test labels\n",
    "\n",
    "path = 'E:\\\\data11\\\\xray_labels2.csv'\n",
    "file = open(path)\n",
    "\n",
    "labeldata = csv.reader(file)\n",
    "labellist = []\n",
    "\n",
    "for  i   in  labeldata:\n",
    "    labellist.append(i)\n",
    "\n",
    "labellist2 = sum(labellist,[]) # sum 함수의 default 값은 0이므로 []로 바꾸어서 리스트 합침.\n",
    "\n",
    "# print(labellist)\n",
    "\n",
    "\n",
    "path2 = 'E:\\\\data11\\\\test_label.csv'\n",
    "file2 = open(path2, 'w')\n",
    "\n",
    "for  i  in  range(7000,7470):\n",
    "    file2.write( str(labellist2[i]) + '\\n' )\n",
    "    \n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ■ Create loader4.py \n",
    "\n",
    " ■ image_load  \n",
    " ■ next_batch  \n",
    " ■ shuffle_batch  \n",
    " ■ label_load  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import   csv\n",
    "import  os\n",
    "import  re\n",
    "import  cv2\n",
    "import  random\n",
    "import  numpy  as  np\n",
    "\n",
    "def  image_load(path):\n",
    "    file_list = os.listdir(path)\n",
    "    file_name = []\n",
    "    for  i  in  file_list:\n",
    "        a = int(  re.sub('[^0-9]', '', i )  ) # 숫자가 아닌것은 '' 로 처리 \n",
    "        file_name.append(a) \n",
    "    file_name.sort()\n",
    "\n",
    "    file_res = [] \n",
    "    for  j  in   file_name:\n",
    "        file_res.append('%s\\\\%d.png' %(path,j)  )\n",
    "\n",
    "    image = []\n",
    "    for  k  in  file_res:\n",
    "        img = cv2.imread(k)\n",
    "        image.append(img)\n",
    "\n",
    "    return  np.array(image)\n",
    "\n",
    "def  label_load( path ):\n",
    "    file = open(path)\n",
    "    labeldata = csv.reader(file)\n",
    "    labellist = []\n",
    "    for  i   in  labeldata:\n",
    "        labellist.append(i)\n",
    "\n",
    "    label = np.array(labellist)\n",
    "    label = label.astype(int)  # 숫자로 변환 \n",
    "    label = np.eye(2)[label]\n",
    "    label = label.reshape(-1,2) \n",
    "    return  label\n",
    "\n",
    "\n",
    "def  shuffle_batch( data_list, label ):\n",
    "    x = np.arange( len( data_list) )\n",
    "    random.shuffle(x)\n",
    "    data_list2 = data_list[x]\n",
    "    label2 = label[x]\n",
    "    return   data_list2, label2 \n",
    "\n",
    "\n",
    "def  next_batch( data1, data2, init,  fina ):\n",
    "    return  data1[ init : fina ],  data2[init : fina] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ● Check train_data and test_data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 32, 32, 3)\n",
      "(7000, 2)\n",
      "(470, 32, 32, 3)\n",
      "(470, 2)\n"
     ]
    }
   ],
   "source": [
    "import loader4\n",
    "\n",
    "train_image='E:\\\\data11\\\\train_resize\\\\'\n",
    "train_label= 'E:\\\\data11\\\\train_label.csv'\n",
    "test_image='E:\\\\data11\\\\test_resize\\\\'\n",
    "test_label='E:\\\\data11\\\\test_label.csv'\n",
    "\n",
    "print(loader4.image_load(train_image).shape)\n",
    "print(loader4.label_load(train_label).shape)\n",
    "print(loader4.image_load(test_image).shape)\n",
    "print(loader4.label_load(test_label).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ Train start !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 32, 32, 3)\n",
      "(7000, 2)\n",
      "(470, 32, 32, 3)\n",
      "(470, 2)\n",
      "(32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\envs\\tf2.0-gpu\\lib\\site-packages\\ipykernel_launcher.py:74: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 470 samples\n",
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 4s 559us/step - loss: 0.8226 - accuracy: 0.5937 - val_loss: 0.6686 - val_accuracy: 0.6149\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 3s 379us/step - loss: 0.6839 - accuracy: 0.6143 - val_loss: 0.6637 - val_accuracy: 0.6085\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 3s 385us/step - loss: 0.6481 - accuracy: 0.6410 - val_loss: 0.6345 - val_accuracy: 0.6277\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 3s 389us/step - loss: 0.6367 - accuracy: 0.6406 - val_loss: 0.6656 - val_accuracy: 0.6340\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 3s 387us/step - loss: 0.6219 - accuracy: 0.6520 - val_loss: 0.6433 - val_accuracy: 0.6170\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 3s 434us/step - loss: 0.6184 - accuracy: 0.6591 - val_loss: 0.6309 - val_accuracy: 0.6404\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 3s 415us/step - loss: 0.6231 - accuracy: 0.6530 - val_loss: 0.6578 - val_accuracy: 0.6128\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 3s 396us/step - loss: 0.6064 - accuracy: 0.6744 - val_loss: 0.6787 - val_accuracy: 0.6170\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 3s 389us/step - loss: 0.6036 - accuracy: 0.6669 - val_loss: 0.6800 - val_accuracy: 0.6128\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.5995 - accuracy: 0.6780 - val_loss: 0.6276 - val_accuracy: 0.6532\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 3s 389us/step - loss: 0.5841 - accuracy: 0.6873 - val_loss: 0.6379 - val_accuracy: 0.6298\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 3s 384us/step - loss: 0.5838 - accuracy: 0.6864 - val_loss: 0.6243 - val_accuracy: 0.6532\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 3s 383us/step - loss: 0.5659 - accuracy: 0.7011 - val_loss: 0.6383 - val_accuracy: 0.6532\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.5698 - accuracy: 0.7034 - val_loss: 0.6201 - val_accuracy: 0.6532\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - 3s 395us/step - loss: 0.5499 - accuracy: 0.7136 - val_loss: 0.6249 - val_accuracy: 0.6532\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 3s 388us/step - loss: 0.5415 - accuracy: 0.7253 - val_loss: 0.6065 - val_accuracy: 0.6745\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 3s 384us/step - loss: 0.5183 - accuracy: 0.7404 - val_loss: 0.6149 - val_accuracy: 0.6809\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 3s 391us/step - loss: 0.5133 - accuracy: 0.7437 - val_loss: 0.6255 - val_accuracy: 0.6532\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 3s 389us/step - loss: 0.4929 - accuracy: 0.7563 - val_loss: 0.6071 - val_accuracy: 0.6681\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.4700 - accuracy: 0.7684 - val_loss: 0.6383 - val_accuracy: 0.6681\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 3s 390us/step - loss: 0.4576 - accuracy: 0.7801 - val_loss: 0.6300 - val_accuracy: 0.6489\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.4319 - accuracy: 0.7946 - val_loss: 0.6305 - val_accuracy: 0.6766\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 3s 385us/step - loss: 0.4113 - accuracy: 0.8037 - val_loss: 0.7187 - val_accuracy: 0.6596\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 3s 384us/step - loss: 0.3884 - accuracy: 0.8236 - val_loss: 0.7054 - val_accuracy: 0.6660\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 3s 387us/step - loss: 0.3707 - accuracy: 0.8344 - val_loss: 0.6634 - val_accuracy: 0.6681\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.3510 - accuracy: 0.8413 - val_loss: 0.7555 - val_accuracy: 0.6255\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 3s 388us/step - loss: 0.3330 - accuracy: 0.8536 - val_loss: 0.7682 - val_accuracy: 0.6511\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 3s 391us/step - loss: 0.3195 - accuracy: 0.8619 - val_loss: 0.7790 - val_accuracy: 0.6404\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 3s 395us/step - loss: 0.2946 - accuracy: 0.8750 - val_loss: 0.7101 - val_accuracy: 0.6830\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 3s 392us/step - loss: 0.2845 - accuracy: 0.8769 - val_loss: 0.8336 - val_accuracy: 0.6596\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 3s 385us/step - loss: 0.2584 - accuracy: 0.8937 - val_loss: 0.7645 - val_accuracy: 0.6745\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 3s 384us/step - loss: 0.2407 - accuracy: 0.8990 - val_loss: 0.8706 - val_accuracy: 0.6617\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 3s 391us/step - loss: 0.2422 - accuracy: 0.8964 - val_loss: 0.9678 - val_accuracy: 0.6787\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.2261 - accuracy: 0.9057 - val_loss: 0.8238 - val_accuracy: 0.6702\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.2171 - accuracy: 0.9144 - val_loss: 0.8292 - val_accuracy: 0.6553\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 3s 387us/step - loss: 0.2137 - accuracy: 0.9127 - val_loss: 0.7316 - val_accuracy: 0.6532\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.2082 - accuracy: 0.9129 - val_loss: 0.8605 - val_accuracy: 0.6340\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 3s 388us/step - loss: 0.1919 - accuracy: 0.9256 - val_loss: 0.9730 - val_accuracy: 0.6681\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 3s 385us/step - loss: 0.1879 - accuracy: 0.9236 - val_loss: 0.8448 - val_accuracy: 0.6298\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.1707 - accuracy: 0.9314 - val_loss: 0.8145 - val_accuracy: 0.6596\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 3s 390us/step - loss: 0.1654 - accuracy: 0.9326 - val_loss: 0.8625 - val_accuracy: 0.6532\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 3s 387us/step - loss: 0.1742 - accuracy: 0.9351 - val_loss: 0.8127 - val_accuracy: 0.6617\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 3s 388us/step - loss: 0.1514 - accuracy: 0.9420 - val_loss: 0.9074 - val_accuracy: 0.6404\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 3s 387us/step - loss: 0.1583 - accuracy: 0.9377 - val_loss: 0.8992 - val_accuracy: 0.6404\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 3s 385us/step - loss: 0.1542 - accuracy: 0.9356 - val_loss: 1.0030 - val_accuracy: 0.6766\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 3s 385us/step - loss: 0.1448 - accuracy: 0.9440 - val_loss: 0.9941 - val_accuracy: 0.6617\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 3s 384us/step - loss: 0.1432 - accuracy: 0.9436 - val_loss: 0.9021 - val_accuracy: 0.6681\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 3s 390us/step - loss: 0.1371 - accuracy: 0.9464 - val_loss: 0.9338 - val_accuracy: 0.6766\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 3s 384us/step - loss: 0.1264 - accuracy: 0.9521 - val_loss: 0.9437 - val_accuracy: 0.6447\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.1282 - accuracy: 0.9526 - val_loss: 0.9723 - val_accuracy: 0.6553\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 3s 389us/step - loss: 0.1202 - accuracy: 0.9543 - val_loss: 1.0707 - val_accuracy: 0.6681\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.1239 - accuracy: 0.9509 - val_loss: 0.8737 - val_accuracy: 0.6787\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 3s 388us/step - loss: 0.1277 - accuracy: 0.9523 - val_loss: 0.9257 - val_accuracy: 0.6766\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 3s 384us/step - loss: 0.1167 - accuracy: 0.9550 - val_loss: 0.9009 - val_accuracy: 0.6617\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 3s 385us/step - loss: 0.1282 - accuracy: 0.9474 - val_loss: 0.9621 - val_accuracy: 0.6660\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 3s 387us/step - loss: 0.1155 - accuracy: 0.9550 - val_loss: 0.9637 - val_accuracy: 0.6638\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 3s 398us/step - loss: 0.1023 - accuracy: 0.9593 - val_loss: 0.9895 - val_accuracy: 0.6660\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 3s 380us/step - loss: 0.0937 - accuracy: 0.9659 - val_loss: 0.9694 - val_accuracy: 0.6702\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 3s 384us/step - loss: 0.1145 - accuracy: 0.9581 - val_loss: 1.0279 - val_accuracy: 0.6787\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 3s 383us/step - loss: 0.0989 - accuracy: 0.9597 - val_loss: 0.9356 - val_accuracy: 0.6723\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - ETA: 0s - loss: 0.1015 - accuracy: 0.96 - 3s 380us/step - loss: 0.1016 - accuracy: 0.9604 - val_loss: 1.0448 - val_accuracy: 0.6638\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 3s 387us/step - loss: 0.1001 - accuracy: 0.9604 - val_loss: 1.0526 - val_accuracy: 0.6574\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.0960 - accuracy: 0.9639 - val_loss: 1.0406 - val_accuracy: 0.6553\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 3s 382us/step - loss: 0.0879 - accuracy: 0.9664 - val_loss: 1.0280 - val_accuracy: 0.6830\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 3s 381us/step - loss: 0.0918 - accuracy: 0.9663 - val_loss: 1.0275 - val_accuracy: 0.6681\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 3s 385us/step - loss: 0.1002 - accuracy: 0.9611 - val_loss: 1.0335 - val_accuracy: 0.6745\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 3s 381us/step - loss: 0.1040 - accuracy: 0.9624 - val_loss: 0.9618 - val_accuracy: 0.6915\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 3s 383us/step - loss: 0.0872 - accuracy: 0.9670 - val_loss: 1.0011 - val_accuracy: 0.6851\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 3s 384us/step - loss: 0.0846 - accuracy: 0.9691 - val_loss: 0.9805 - val_accuracy: 0.6723\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 3s 392us/step - loss: 0.0938 - accuracy: 0.9620 - val_loss: 0.9936 - val_accuracy: 0.6702\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 3s 388us/step - loss: 0.0972 - accuracy: 0.9644 - val_loss: 1.0120 - val_accuracy: 0.6574\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.0821 - accuracy: 0.9696 - val_loss: 1.1142 - val_accuracy: 0.6723\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.0809 - accuracy: 0.9700 - val_loss: 0.9525 - val_accuracy: 0.6404\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 3s 385us/step - loss: 0.0802 - accuracy: 0.9694 - val_loss: 1.0416 - val_accuracy: 0.6660\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 3s 383us/step - loss: 0.0753 - accuracy: 0.9737 - val_loss: 1.0767 - val_accuracy: 0.6617\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.0832 - accuracy: 0.9697 - val_loss: 0.9684 - val_accuracy: 0.6723\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 3s 388us/step - loss: 0.0687 - accuracy: 0.9726 - val_loss: 1.0823 - val_accuracy: 0.6596\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 3s 384us/step - loss: 0.0754 - accuracy: 0.9717 - val_loss: 1.0915 - val_accuracy: 0.6511\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 3s 388us/step - loss: 0.0791 - accuracy: 0.9666 - val_loss: 1.0858 - val_accuracy: 0.6809\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 3s 385us/step - loss: 0.0835 - accuracy: 0.9681 - val_loss: 0.9971 - val_accuracy: 0.6660\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.0814 - accuracy: 0.9706 - val_loss: 0.9607 - val_accuracy: 0.6681\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 3s 382us/step - loss: 0.0878 - accuracy: 0.9674 - val_loss: 1.0837 - val_accuracy: 0.6957\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 3s 386us/step - loss: 0.0624 - accuracy: 0.9767 - val_loss: 1.0536 - val_accuracy: 0.6660\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 3s 389us/step - loss: 0.0766 - accuracy: 0.9701 - val_loss: 0.9705 - val_accuracy: 0.6702\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 3s 395us/step - loss: 0.0706 - accuracy: 0.9736 - val_loss: 0.9056 - val_accuracy: 0.6957\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 3s 406us/step - loss: 0.0708 - accuracy: 0.9756 - val_loss: 1.0535 - val_accuracy: 0.6723\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 3s 390us/step - loss: 0.0729 - accuracy: 0.9741 - val_loss: 1.0761 - val_accuracy: 0.6766\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 3s 387us/step - loss: 0.0749 - accuracy: 0.9761 - val_loss: 1.2102 - val_accuracy: 0.6723\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 3s 393us/step - loss: 0.0745 - accuracy: 0.9719 - val_loss: 0.9831 - val_accuracy: 0.6553\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 3s 401us/step - loss: 0.0653 - accuracy: 0.9743 - val_loss: 1.0932 - val_accuracy: 0.6638\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 3s 430us/step - loss: 0.0664 - accuracy: 0.9750 - val_loss: 1.0105 - val_accuracy: 0.6745\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 3s 403us/step - loss: 0.0609 - accuracy: 0.9789 - val_loss: 0.9647 - val_accuracy: 0.6681\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 3s 400us/step - loss: 0.0638 - accuracy: 0.9773 - val_loss: 1.0506 - val_accuracy: 0.6894\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 3s 390us/step - loss: 0.0569 - accuracy: 0.9793 - val_loss: 1.0532 - val_accuracy: 0.6574\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 3s 387us/step - loss: 0.0627 - accuracy: 0.9759 - val_loss: 1.0961 - val_accuracy: 0.6957\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 3s 384us/step - loss: 0.0748 - accuracy: 0.9730 - val_loss: 0.9761 - val_accuracy: 0.7000\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 3s 384us/step - loss: 0.0730 - accuracy: 0.9729 - val_loss: 1.0233 - val_accuracy: 0.6809\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 3s 379us/step - loss: 0.0681 - accuracy: 0.9759 - val_loss: 1.0244 - val_accuracy: 0.6979\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 3s 395us/step - loss: 0.0665 - accuracy: 0.9753 - val_loss: 1.0286 - val_accuracy: 0.6766\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 3s 401us/step - loss: 0.0533 - accuracy: 0.9820 - val_loss: 1.1389 - val_accuracy: 0.6702\n",
      "CNN Error: 32.98%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, save_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import loader4\n",
    "\n",
    "batch_size = 28\n",
    "num_classes = 2\n",
    "epochs = 100\n",
    " \n",
    "train_image='E:\\\\data11\\\\train_resize\\\\'\n",
    "train_label= 'E:\\\\data11\\\\train_label.csv'\n",
    "test_image='E:\\\\data11\\\\test_resize\\\\'\n",
    "test_label='E:\\\\data11\\\\test_label.csv'\n",
    "\n",
    "\n",
    "x_train = loader4.image_load(train_image)\n",
    "y_train = loader4.label_load(train_label)\n",
    "x_test = loader4.image_load(test_image)\n",
    "y_test = loader4.label_load(test_label)      \n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(x_train.shape[1:])\n",
    "\n",
    "#(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "# One hot Encoding\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    " \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    " \n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    " \n",
    "hist = model.fit(x_train, y_train, validation_data=(x_test, y_test), nb_epoch=epochs, batch_size=batch_size, verbose=1)\n",
    " \n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\n",
    " \n",
    "save_model(model, \"E:\\data11\\\\models\\\\result2.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf2.0-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
